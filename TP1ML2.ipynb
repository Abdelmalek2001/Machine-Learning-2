{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h2 style=\"color: #f39c12; font-size: 24px; font-weight: bold;\">üß© Partie 1 : Pr√©sentation des Biblioth√®ques Cl√©s</h2>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7stSPw8G2qVS",
        "outputId": "6f354f87-a831-4278-8aa9-77b31cfaf422"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting gymnasium\n",
            "  Downloading gymnasium-1.1.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (2.0.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (4.12.2)\n",
            "Collecting farama-notifications>=0.0.1 (from gymnasium)\n",
            "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl.metadata (558 bytes)\n",
            "Downloading gymnasium-1.1.1-py3-none-any.whl (965 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m965.4/965.4 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Installing collected packages: farama-notifications, gymnasium\n",
            "Successfully installed farama-notifications-0.0.4 gymnasium-1.1.1\n"
          ]
        }
      ],
      "source": [
        "!pip install gymnasium"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NKLSQOjjZWU",
        "outputId": "88910d91-2c21-483c-d881-b9956c154609"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gymnasium[classic-control] in /usr/local/lib/python3.11/dist-packages (1.1.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[classic-control]) (2.0.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[classic-control]) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[classic-control]) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium[classic-control]) (0.0.4)\n",
            "Collecting pygame>=2.1.3 (from gymnasium[classic-control])\n",
            "  Downloading pygame-2.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Downloading pygame-2.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.0 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pygame\n",
            "Successfully installed pygame-2.6.1\n"
          ]
        }
      ],
      "source": [
        "pip install \"gymnasium[classic-control]\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9lNgxA33asI",
        "outputId": "8858e138-d513-4442-e51b-c2816bd59b1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gymnasium est install√© avec succ√®s!\n"
          ]
        }
      ],
      "source": [
        "import gymnasium as gym\n",
        "print(\"Gymnasium est install√© avec succ√®s!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h3 style=\"color: #2ecc71; font-size: 22px; font-weight: bold;\">üèãÔ∏è Exercice 1 : D√©couverte et Exploration d‚Äôun Environnement Gym</h3>\n",
        "\n",
        "<h3 style=\"color: #3498db; font-size: 22px; font-weight: bold;\">üß© Exercice 2 : Manipulation des Observations et R√©compenses</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Gw3n4zK26If",
        "outputId": "db3ddcc4-995d-4e42-fe6f-fa218b98dde3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Espaces d'actions : Discrete(2)\n",
            "Espaces d'observation: Box([-4.8               -inf -0.41887903        -inf], [4.8               inf 0.41887903        inf], (4,), float32)\n",
            "Action : 1, Observation : [-1.3250198e-04  2.3863684e-01  9.3355188e-03 -2.7075213e-01], Reward : 1.0\n",
            "Action : 0, Observation : [0.00464023 0.04338292 0.00392048 0.0248606 ], Reward : 1.0\n",
            "Action : 0, Observation : [ 0.00550789 -0.15179503  0.00441769  0.3187779 ], Reward : 1.0\n",
            "Action : 1, Observation : [0.00247199 0.04326373 0.01079325 0.02749141], Reward : 1.0\n",
            "Action : 1, Observation : [ 0.00333727  0.23822924  0.01134307 -0.26176667], Reward : 1.0\n",
            "Action : 1, Observation : [ 0.00810185  0.43318745  0.00610774 -0.5508504 ], Reward : 1.0\n",
            "Action : 0, Observation : [ 0.0167656   0.23798026 -0.00490927 -0.2562494 ], Reward : 1.0\n",
            "Action : 0, Observation : [ 0.02152521  0.04292874 -0.01003425  0.03488104], Reward : 1.0\n",
            "Action : 0, Observation : [ 0.02238378 -0.15204789 -0.00933663  0.32438123], Reward : 1.0\n",
            "Action : 0, Observation : [ 0.01934282 -0.34703568 -0.00284901  0.6141052 ], Reward : 1.0\n",
            "Action : 1, Observation : [ 0.01240211 -0.15187402  0.0094331   0.32052633], Reward : 1.0\n",
            "Action : 1, Observation : [0.00936463 0.04311233 0.01584362 0.03083311], Reward : 1.0\n",
            "Action : 0, Observation : [ 0.01022688 -0.1522332   0.01646028  0.32847247], Reward : 1.0\n",
            "Action : 1, Observation : [0.00718221 0.0426506  0.02302973 0.04102547], Reward : 1.0\n",
            "Action : 0, Observation : [ 0.00803522 -0.1527939   0.02385024  0.34088463], Reward : 1.0\n",
            "Action : 1, Observation : [0.00497935 0.04198074 0.03066794 0.05581707], Reward : 1.0\n",
            "Action : 0, Observation : [ 0.00581896 -0.15356721  0.03178428  0.35801604], Reward : 1.0\n",
            "Action : 1, Observation : [0.00274762 0.0410888  0.0389446  0.07552248], Reward : 1.0\n",
            "Action : 0, Observation : [ 0.00356939 -0.1545692   0.04045505  0.38023376], Reward : 1.0\n",
            "Action : 1, Observation : [0.00047801 0.03995563 0.04805972 0.1005758 ], Reward : 1.0\n",
            "Action : 1, Observation : [ 0.00127712  0.23435704  0.05007124 -0.1765655 ], Reward : 1.0\n",
            "Action : 1, Observation : [ 0.00596426  0.42872798  0.04653993 -0.45304173], Reward : 1.0\n",
            "Action : 0, Observation : [ 0.01453882  0.23297986  0.0374791  -0.14605968], Reward : 1.0\n",
            "Action : 1, Observation : [ 0.01919842  0.4275456   0.0345579  -0.42668706], Reward : 1.0\n",
            "Action : 1, Observation : [ 0.02774933  0.6221615   0.02602416 -0.70827854], Reward : 1.0\n",
            "Action : 1, Observation : [ 0.04019256  0.8169135   0.01185859 -0.99265736], Reward : 1.0\n",
            "Action : 0, Observation : [ 0.05653083  0.62163484 -0.00799456 -0.69627374], Reward : 1.0\n",
            "Action : 1, Observation : [ 0.06896353  0.81686676 -0.02192003 -0.9914626 ], Reward : 1.0\n",
            "Action : 0, Observation : [ 0.08530086  0.6220449  -0.04174929 -0.705744  ], Reward : 1.0\n",
            "Action : 0, Observation : [ 0.09774176  0.42752552 -0.05586417 -0.4264899 ], Reward : 1.0\n",
            "Action : 1, Observation : [ 0.10629227  0.6233924  -0.06439397 -0.7362474 ], Reward : 1.0\n",
            "Action : 0, Observation : [ 0.11876012  0.4292162  -0.07911891 -0.46450552], Reward : 1.0\n",
            "Action : 1, Observation : [ 0.12734444  0.6253618  -0.08840902 -0.78104025], Reward : 1.0\n",
            "Action : 0, Observation : [ 0.13985167  0.43155918 -0.10402983 -0.51743007], Reward : 1.0\n",
            "Action : 1, Observation : [ 0.14848286  0.62798023 -0.11437843 -0.8409984 ], Reward : 1.0\n",
            "Action : 1, Observation : [ 0.16104247  0.82446223 -0.13119839 -1.1673497 ], Reward : 1.0\n",
            "Action : 1, Observation : [ 0.17753172  1.0210242  -0.1545454  -1.4981204 ], Reward : 1.0\n",
            "Action : 1, Observation : [ 0.1979522  1.2176495 -0.1845078 -1.8347988], Reward : 1.0\n",
            "Action : 0, Observation : [ 0.2223052   1.0249859  -0.22120377 -1.6046468 ], Reward : 1.0\n",
            "Action : 1, Observation : [-0.01621787  0.1947117   0.02171155 -0.25175953], Reward : 1.0\n",
            "Action : 0, Observation : [-0.01232364 -0.00071345  0.01667636  0.04769178], Reward : 1.0\n",
            "Action : 0, Observation : [-0.01233791 -0.1960705   0.01763019  0.34558925], Reward : 1.0\n",
            "Action : 0, Observation : [-0.01625932 -0.39143875  0.02454198  0.6437791 ], Reward : 1.0\n",
            "Action : 0, Observation : [-0.02408809 -0.586894    0.03741756  0.9440883 ], Reward : 1.0\n",
            "Action : 0, Observation : [-0.03582597 -0.7824995   0.05629932  1.2482893 ], Reward : 1.0\n",
            "Action : 1, Observation : [-0.05147596 -0.58814275  0.08126511  0.9737594 ], Reward : 1.0\n",
            "Action : 1, Observation : [-0.06323881 -0.39419955  0.1007403   0.70767033], Reward : 1.0\n",
            "Action : 0, Observation : [-0.07112281 -0.59056205  0.1148937   1.0302883 ], Reward : 1.0\n",
            "Action : 1, Observation : [-0.08293405 -0.39714068  0.13549948  0.7757736 ], Reward : 1.0\n",
            "Action : 0, Observation : [-0.09087686 -0.59384024  0.15101494  1.1078335 ], Reward : 1.0\n",
            "Action : 1, Observation : [-0.10275367 -0.40099052  0.17317161  0.86608106], Reward : 1.0\n",
            "Action : 1, Observation : [-0.11077347 -0.20859462  0.19049324  0.632462  ], Reward : 1.0\n",
            "Action : 1, Observation : [-0.11494537 -0.01656884  0.20314248  0.4053006 ], Reward : 1.0\n",
            "Action : 1, Observation : [-0.11527675  0.17518051  0.21124849  0.18290484], Reward : 1.0\n",
            "Action : 1, Observation : [ 0.03133435  0.14711177 -0.03849805 -0.29462773], Reward : 1.0\n",
            "Action : 0, Observation : [ 0.03427659 -0.04744077 -0.04439061 -0.01433076], Reward : 1.0\n",
            "Action : 0, Observation : [ 0.03332777 -0.24189892 -0.04467722  0.26402256], Reward : 1.0\n",
            "Action : 1, Observation : [ 0.02848979 -0.04616869 -0.03939677 -0.04241055], Reward : 1.0\n",
            "Action : 1, Observation : [ 0.02756642  0.14949541 -0.04024498 -0.3472586 ], Reward : 1.0\n",
            "Action : 1, Observation : [ 0.03055633  0.345166   -0.04719015 -0.6523557 ], Reward : 1.0\n",
            "Action : 1, Observation : [ 0.03745965  0.5409123  -0.06023727 -0.95951694], Reward : 1.0\n",
            "Action : 1, Observation : [ 0.04827789  0.73679    -0.07942761 -1.2704997 ], Reward : 1.0\n",
            "Action : 1, Observation : [ 0.06301369  0.932831   -0.1048376  -1.5869613 ], Reward : 1.0\n",
            "Action : 0, Observation : [ 0.08167031  0.7390997  -0.13657683 -1.3287257 ], Reward : 1.0\n",
            "Action : 0, Observation : [ 0.0964523   0.5459397  -0.16315134 -1.0817126 ], Reward : 1.0\n",
            "Action : 0, Observation : [ 0.1073711   0.35330272 -0.18478559 -0.8443484 ], Reward : 1.0\n",
            "Action : 1, Observation : [ 0.11443716  0.5504002  -0.20167255 -1.1889797 ], Reward : 1.0\n",
            "Action : 1, Observation : [ 0.12544516  0.74748176 -0.22545215 -1.5375013 ], Reward : 1.0\n",
            "Action : 0, Observation : [-0.0434729  -0.21755858  0.04203613  0.33350092], Reward : 1.0\n",
            "Action : 1, Observation : [-0.04782407 -0.02305935  0.04870615  0.05436478], Reward : 1.0\n",
            "Action : 0, Observation : [-0.04828526 -0.21884462  0.04979344  0.36200836], Reward : 1.0\n",
            "Action : 0, Observation : [-0.05266215 -0.41463766  0.05703361  0.6699671 ], Reward : 1.0\n",
            "Action : 1, Observation : [-0.0609549  -0.2203531   0.07043295  0.39577293], Reward : 1.0\n",
            "Action : 0, Observation : [-0.06536196 -0.41640002  0.07834841  0.70980436], Reward : 1.0\n",
            "Action : 0, Observation : [-0.07368997 -0.6125146   0.0925445   1.0260848 ], Reward : 1.0\n",
            "Action : 0, Observation : [-0.08594026 -0.8087387   0.1130662   1.3463306 ], Reward : 1.0\n",
            "Action : 0, Observation : [-0.10211503 -1.005086    0.1399928   1.6721417 ], Reward : 1.0\n",
            "Action : 0, Observation : [-0.12221675 -1.201529    0.17343564  2.0049472 ], Reward : 1.0\n",
            "Action : 1, Observation : [-0.14624733 -1.0085884   0.21353458  1.7706128 ], Reward : 1.0\n",
            "Action : 0, Observation : [-0.03854768 -0.1558434   0.00876892  0.28065318], Reward : 1.0\n",
            "Action : 1, Observation : [-0.04166455  0.03915237  0.01438199 -0.0092512 ], Reward : 1.0\n",
            "Action : 0, Observation : [-0.0408815  -0.15617286  0.01419696  0.28793448], Reward : 1.0\n",
            "Action : 0, Observation : [-0.04400496 -0.35149437  0.01995565  0.585061  ], Reward : 1.0\n",
            "Action : 0, Observation : [-0.05103485 -0.5468901   0.03165687  0.88396275], Reward : 1.0\n",
            "Action : 1, Observation : [-0.06197265 -0.35221195  0.04933613  0.6013975 ], Reward : 1.0\n",
            "Action : 0, Observation : [-0.06901689 -0.54798806  0.06136408  0.9092033 ], Reward : 1.0\n",
            "Action : 0, Observation : [-0.07997665 -0.7438845   0.07954814  1.2205245 ], Reward : 1.0\n",
            "Action : 1, Observation : [-0.09485434 -0.54987276  0.10395864  0.9537897 ], Reward : 1.0\n",
            "Action : 0, Observation : [-0.1058518  -0.7462281   0.12303443  1.2772413 ], Reward : 1.0\n",
            "Action : 0, Observation : [-0.12077636 -0.94268495  0.14857925  1.60578   ], Reward : 1.0\n",
            "Action : 1, Observation : [-0.13963005 -0.7495998   0.18069485  1.3628651 ], Reward : 1.0\n",
            "Action : 1, Observation : [-0.15462205 -0.55714244  0.20795216  1.1317147 ], Reward : 1.0\n",
            "Action : 1, Observation : [-0.1657649  -0.36525804  0.23058645  0.9107874 ], Reward : 1.0\n",
            "Action : 1, Observation : [-0.0394484   0.16102141 -0.04869903 -0.31134677], Reward : 1.0\n",
            "Action : 1, Observation : [-0.03622798  0.35680214 -0.05492596 -0.61898154], Reward : 1.0\n",
            "Action : 0, Observation : [-0.02909193  0.16248864 -0.06730559 -0.34409097], Reward : 1.0\n",
            "Action : 0, Observation : [-0.02584216 -0.03161449 -0.07418741 -0.07336839], Reward : 1.0\n",
            "Action : 0, Observation : [-0.02647445 -0.2255988  -0.07565477  0.19501661], Reward : 1.0\n",
            "Action : 0, Observation : [-0.03098643 -0.41956162 -0.07175445  0.46290728], Reward : 1.0\n",
            "Action : 0, Observation : [-0.03937766 -0.6136     -0.0624963   0.7321383 ], Reward : 1.0\n"
          ]
        }
      ],
      "source": [
        "import gymnasium as gym\n",
        "env = gym.make(\"CartPole-v1\", render_mode=\"human\")\n",
        "observation, _ = env.reset()\n",
        "\n",
        "print(f\"Espaces d'actions : {env.action_space}\")\n",
        "print(f\"Espaces d'observation: {env.observation_space}\")\n",
        "\n",
        "for _ in range(100):\n",
        "    action = env.action_space.sample()\n",
        "    observation, reward, done, _, _ = env.step(action)\n",
        "\n",
        "    print(f\"Action : {action}, Observation : {observation}, Reward : {reward}\")\n",
        "\n",
        "    if done:\n",
        "        observation, _ = env.reset()\n",
        "\n",
        "env.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h3 style=\"color: #e74c3c; font-size: 22px; font-weight: bold;\">üïπÔ∏è Exercice 3 : Contr√¥le Manuel de l‚ÄôAgent</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YgrETrWG4G4P",
        "outputId": "6ee532b6-538e-4541-eaee-7af6256f7580"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Entrez une action (0 = gauche, 1 = droite) : 1\n",
            "Action : 1, Observation : [ 0.03045256  0.2409437   0.02782407 -0.2710724 ], Reward : 1.0\n",
            "Entrez une action (0 = gauche, 1 = droite) : 1\n",
            "Action : 1, Observation : [ 0.03527144  0.43565777  0.02240262 -0.55485123], Reward : 1.0\n",
            "Entrez une action (0 = gauche, 1 = droite) : 1\n",
            "Action : 1, Observation : [ 0.0439846   0.6304581   0.01130559 -0.8403926 ], Reward : 1.0\n",
            "Entrez une action (0 = gauche, 1 = droite) : 1\n",
            "Action : 1, Observation : [ 0.05659376  0.8254239  -0.00550226 -1.1294988 ], Reward : 1.0\n",
            "Entrez une action (0 = gauche, 1 = droite) : 1\n",
            "Action : 1, Observation : [ 0.07310224  1.0206175  -0.02809223 -1.4239024 ], Reward : 1.0\n",
            "Entrez une action (0 = gauche, 1 = droite) : 1\n",
            "Action : 1, Observation : [ 0.09351458  1.2160753  -0.05657028 -1.7252314 ], Reward : 1.0\n",
            "Entrez une action (0 = gauche, 1 = droite) : 1\n",
            "Action : 1, Observation : [ 0.11783609  1.4117968  -0.09107491 -2.034967  ], Reward : 1.0\n",
            "Entrez une action (0 = gauche, 1 = droite) : 1\n",
            "Action : 1, Observation : [ 0.14607203  1.6077317  -0.13177425 -2.3543901 ], Reward : 1.0\n",
            "Entrez une action (0 = gauche, 1 = droite) : 1\n",
            "Action : 1, Observation : [ 0.17822666  1.8037635  -0.17886205 -2.684518  ], Reward : 1.0\n",
            "Entrez une action (0 = gauche, 1 = droite) : 1\n",
            "Action : 1, Observation : [ 0.21430193  1.9996916  -0.23255242 -3.0260272 ], Reward : 1.0\n",
            "√âpisode termin√© ! Dur√©e totale : 10 √©tapes.\n"
          ]
        }
      ],
      "source": [
        "import gymnasium as gym\n",
        "\n",
        "env = gym.make(\"CartPole-v1\", render_mode=\"human\")\n",
        "observation, info = env.reset()  # On r√©cup√®re aussi 'info' m√™me si on ne l'utilise pas\n",
        "\n",
        "steps = 0\n",
        "terminated = False\n",
        "truncated = False\n",
        "\n",
        "while not terminated and not truncated:\n",
        "    action = input(\"Entrez une action (0 = gauche, 1 = droite) : \")\n",
        "\n",
        "    if action not in [\"0\", \"1\"]:\n",
        "        print(\"Entr√©e invalide ! Veuillez entrer 0 ou 1.\")\n",
        "        continue\n",
        "\n",
        "    action = int(action)\n",
        "    observation, reward, terminated, truncated, info = env.step(action)\n",
        "\n",
        "    print(f\"Action : {action}, Observation : {observation}, Reward : {reward}\")\n",
        "\n",
        "    steps += 1\n",
        "\n",
        "print(f\"√âpisode termin√© ! Dur√©e totale : {steps} √©tapes.\")\n",
        "env.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h3 style=\"color: #8e44ad; font-size: 22px; font-weight: bold;\">üìä Exercice 4 : √âvaluation des Performances d‚Äôune Politique Al√©atoire</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQQoXnQ-4XwX",
        "outputId": "f476365c-67fe-434d-9e84-0e3adc5a184e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "√âpisode 1 termin√© en 43 √©tapes.\n",
            "√âpisode 2 termin√© en 12 √©tapes.\n",
            "√âpisode 3 termin√© en 19 √©tapes.\n",
            "√âpisode 4 termin√© en 14 √©tapes.\n",
            "√âpisode 5 termin√© en 24 √©tapes.\n",
            "√âpisode 6 termin√© en 17 √©tapes.\n",
            "√âpisode 7 termin√© en 19 √©tapes.\n",
            "√âpisode 8 termin√© en 21 √©tapes.\n",
            "√âpisode 9 termin√© en 12 √©tapes.\n",
            "√âpisode 10 termin√© en 9 √©tapes.\n",
            "\n",
            "Dur√©e moyenne sur 10 √©pisodes : 19.00 √©tapes.\n"
          ]
        }
      ],
      "source": [
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "\n",
        "env = gym.make(\"CartPole-v1\")\n",
        "\n",
        "num_episodes = 10\n",
        "durations = []\n",
        "\n",
        "for episode in range(num_episodes):\n",
        "    observation, _ = env.reset()\n",
        "    done = False\n",
        "    steps = 0\n",
        "\n",
        "    while not done:\n",
        "        action = env.action_space.sample()\n",
        "        observation, reward, done, _, _ = env.step(action)\n",
        "        steps += 1\n",
        "\n",
        "    durations.append(steps)\n",
        "    print(f\"√âpisode {episode + 1} termin√© en {steps} √©tapes.\")\n",
        "\n",
        "average_duration = np.mean(durations)\n",
        "print(f\"\\nDur√©e moyenne sur {num_episodes} √©pisodes : {average_duration:.2f} √©tapes.\")\n",
        "\n",
        "env.close()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
